{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11501850,"sourceType":"datasetVersion","datasetId":7210985}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This repository is designed for use in Kaggle. If you would like to use it in Google\n# Colab, please change requirements_kaggle.txt to requirements.txt\n\n# Note: If the clone failed, please check at the right side bar if Session options > \n# Internet is on. You would need to verify your phone number if you are turning it \n# on for the first time.\n\n# Remember to turn on Session options > Persistence > Files only, \n# else your files might be lost.\n\n# Clone the git repository\n!git clone https://github.com/IsaacSzeccl/APAI3010_Realfill.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7M37t-cRkNDf","outputId":"deba5e20-1f49-45db-b53b-096217ceafd9","trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:39:20.195984Z","iopub.execute_input":"2025-04-23T04:39:20.196256Z","iopub.status.idle":"2025-04-23T04:39:20.334742Z","shell.execute_reply.started":"2025-04-23T04:39:20.196213Z","shell.execute_reply":"2025-04-23T04:39:20.333813Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'APAI3010_Realfill' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd APAI3010_Realfill/realfill\n%ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTXUPQrrtMZF","outputId":"ff54182e-d63f-4289-f084-4481067b874c","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:43:53.009823Z","iopub.execute_input":"2025-04-24T14:43:53.010134Z","iopub.status.idle":"2025-04-24T14:43:53.135200Z","shell.execute_reply.started":"2025-04-24T14:43:53.010108Z","shell.execute_reply":"2025-04-24T14:43:53.134339Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/APAI3010_Realfill/realfill\n\u001b[0m\u001b[01;34mAPAI3010_Realfill\u001b[0m/  infer.py   README.md                requirements.txt\n\u001b[01;34mdata\u001b[0m/               LICENSE    realfill.zip             train_realfill.ipynb\n\u001b[01;34mflowerwoman-model\u001b[0m/  model.zip  requirements_kaggle.txt  train_realfill.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -r requirements_kaggle.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hcWLJk3kq3i","outputId":"b741d90d-7448-4647-f4c1-f7518431d8de","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:43:53.136238Z","iopub.execute_input":"2025-04-24T14:43:53.136504Z","iopub.status.idle":"2025-04-24T14:46:46.603103Z","shell.execute_reply.started":"2025-04-24T14:43:53.136483Z","shell.execute_reply":"2025-04-24T14:46:46.602137Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: diffusers==0.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements_kaggle.txt (line 1)) (0.32.2)\nCollecting accelerate==1.5.2 (from -r requirements_kaggle.txt (line 2))\n  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\nCollecting transformers==4.51.3 (from -r requirements_kaggle.txt (line 3))\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_kaggle.txt (line 4)) (0.14.0)\nRequirement already satisfied: huggingface-hub==0.30.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements_kaggle.txt (line 5)) (0.30.2)\nCollecting torch==2.6.0 (from -r requirements_kaggle.txt (line 6))\n  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting torchvision==0.21.0 (from -r requirements_kaggle.txt (line 7))\n  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\nCollecting ftfy==6.3.1 (from -r requirements_kaggle.txt (line 8))\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tensorboard==2.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_kaggle.txt (line 9)) (2.18.0)\nRequirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements_kaggle.txt (line 10)) (3.1.6)\nCollecting bitsandbytes (from -r requirements_kaggle.txt (line 11))\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting xformers (from -r requirements_kaggle.txt (line 12))\n  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (8.6.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (3.18.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (0.5.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (11.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.5.2->-r requirements_kaggle.txt (line 2)) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.5.2->-r requirements_kaggle.txt (line 2)) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.5.2->-r requirements_kaggle.txt (line 2)) (6.0.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->-r requirements_kaggle.txt (line 3)) (0.21.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3->-r requirements_kaggle.txt (line 3)) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements_kaggle.txt (line 5)) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements_kaggle.txt (line 5)) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements_kaggle.txt (line 6)) (3.4.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements_kaggle.txt (line 6)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements_kaggle.txt (line 6)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements_kaggle.txt (line 6)) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements_kaggle.txt (line 6)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements_kaggle.txt (line 6)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch==2.6.0->-r requirements_kaggle.txt (line 6))\n  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements_kaggle.txt (line 6)) (1.13.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy==6.3.1->-r requirements_kaggle.txt (line 8)) (0.2.13)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (1.70.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.18.0->-r requirements_kaggle.txt (line 9)) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2==3.1.6->-r requirements_kaggle.txt (line 10)) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->-r requirements_kaggle.txt (line 6)) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2.4.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (3.21.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->diffusers==0.32.2->-r requirements_kaggle.txt (line 1)) (2024.2.0)\nDownloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, transformers, accelerate, xformers, torchvision, bitsandbytes\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu124\n    Uninstalling torch-2.5.1+cu124:\n      Successfully uninstalled torch-2.5.1+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.3.0\n    Uninstalling accelerate-1.3.0:\n      Successfully uninstalled accelerate-1.3.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu124\n    Uninstalling torchvision-0.20.1+cu124:\n      Successfully uninstalled torchvision-0.20.1+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\ntorchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.5.2 bitsandbytes-0.45.5 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0 transformers-4.51.3 triton-3.2.0 xformers-0.0.29.post3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Turn on accelerator\n\nfrom accelerate.utils import write_basic_config\nwrite_basic_config()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYgiy8a9k5yA","outputId":"bc0c6abf-a9fc-4c12-c51e-db4c4b55ab6c","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:46:46.606472Z","iopub.execute_input":"2025-04-24T14:46:46.606788Z","iopub.status.idle":"2025-04-24T14:46:51.774218Z","shell.execute_reply.started":"2025-04-24T14:46:46.606760Z","shell.execute_reply":"2025-04-24T14:46:51.773608Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\n# Building environment variables\n# For training\nos.environ[\"TRAIN_DIR\"] = \"data/flowerwoman\"\nos.environ[\"MODEL_NAME\"] = \"stabilityai/stable-diffusion-2-inpainting\"\nos.environ[\"OUTPUT_DIR\"] = \"flowerwoman-model\"\nos.environ['PRECISION_ARG'] = '--mixed_precision=fp16'\n\n# For inference\nos.environ[\"VAL_IMG\"] = \"data/flowerwoman/target/target.png\"\nos.environ[\"VAL_MASK\"] = \"data/flowerwoman/target/mask.png\"\nos.environ[\"OUTPUT_IMG_DIR\"] = \"flowerwoman-results\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:46:51.774888Z","iopub.execute_input":"2025-04-24T14:46:51.775186Z","iopub.status.idle":"2025-04-24T14:46:51.779467Z","shell.execute_reply.started":"2025-04-24T14:46:51.775160Z","shell.execute_reply":"2025-04-24T14:46:51.778769Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# For checking if the path is valid\n!ls $TRAIN_DIR\n!ls $OUTPUT_DIR\n!ls $VAL_IMG\n!ls $VAL_MASK\n!mkdir $OUTPUT_IMG_DIR\n!ls $OUTPUT_IMG_DIR\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:46:51.780083Z","iopub.execute_input":"2025-04-24T14:46:51.780251Z","iopub.status.idle":"2025-04-24T14:46:52.552884Z","shell.execute_reply.started":"2025-04-24T14:46:51.780230Z","shell.execute_reply":"2025-04-24T14:46:52.551813Z"}},"outputs":[{"name":"stdout","text":"ref  target\ncheckpoint-100\t checkpoint-1600  checkpoint-400     logs\ncheckpoint-1000  checkpoint-1700  checkpoint-500     model_index.json\ncheckpoint-1100  checkpoint-1800  checkpoint-600     scheduler\ncheckpoint-1200  checkpoint-1900  checkpoint-700     text_encoder\ncheckpoint-1300  checkpoint-200   checkpoint-800     tokenizer\ncheckpoint-1400  checkpoint-2000  checkpoint-900     unet\ncheckpoint-1500  checkpoint-300   feature_extractor  vae\ndata/flowerwoman/target/target.png\ndata/flowerwoman/target/mask.png\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:42:01.446663Z","iopub.execute_input":"2025-04-23T04:42:01.446969Z","iopub.status.idle":"2025-04-23T04:42:01.451110Z","shell.execute_reply.started":"2025-04-23T04:42:01.446939Z","shell.execute_reply":"2025-04-23T04:42:01.450348Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# For training\n\n!accelerate launch train_realfill.py \\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\n  --train_data_dir=$TRAIN_DIR \\\n  --output_dir=$OUTPUT_DIR \\\n  --resolution=512 \\\n  --train_batch_size=16 \\\n  --gradient_accumulation_steps=1 \\\n  --unet_learning_rate=2e-4 \\\n  --text_encoder_learning_rate=4e-5 \\\n  --lr_scheduler=\"constant\" \\\n  --lr_warmup_steps=100 \\\n  --max_train_steps=2000 \\\n  --lora_rank=8 \\\n  --lora_dropout=0.1 \\\n  --lora_alpha=16 \\\n  --resume_from_checkpoint=\"latest\" \\\n  --report_to tensorboard \\\n  --validation_steps 100 \\\n  --checkpointing_steps 100 \\\n  $PRECISION_ARG \\\n  --use_8bit_adam \\\n  --set_grads_to_none \\\n  --enable_xformers_memory_efficient_attention","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQexbUktpzdp","outputId":"779ff88a-02c5-4c6f-d681-fbbcb7e7b9e1","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:10:36.568196Z","iopub.execute_input":"2025-04-24T10:10:36.568725Z","iopub.status.idle":"2025-04-24T10:10:39.377622Z","shell.execute_reply.started":"2025-04-24T10:10:36.568703Z","shell.execute_reply":"2025-04-24T10:10:39.376681Z"}},"outputs":[{"name":"stdout","text":"^C\nTraceback (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 5, in <module>\n    from accelerate.commands.accelerate_cli import main\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/__init__.py\", line 16, in <module>\n    from .accelerator import Accelerator\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\", line 36, in <module>\n    from accelerate.utils.imports import is_torchao_available\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/__init__.py\", line 14, in <module>\n    from .ao import convert_model_to_fp8_ao, filter_first_and_last_linear_layers, has_ao_layers\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/ao.py\", line 28, in <module>\n    from torchao.float8.float8_linear import Float8LinearConfig\n  File \"/usr/local/lib/python3.11/dist-packages/torchao/__init__.py\", line 41, in <module>\n    from torchao.quantization import (\n  File \"/usr/local/lib/python3.11/dist-packages/torchao/quantization/__init__.py\", line 1, in <module>\n    from torchao.kernel import (\n  File \"/usr/local/lib/python3.11/dist-packages/torchao/kernel/__init__.py\", line 1, in <module>\n    from torchao.kernel.bsr_triton_ops import bsr_dense_addmm\n  File \"/usr/local/lib/python3.11/dist-packages/torchao/kernel/bsr_triton_ops.py\", line 16, in <module>\n    from torch._dynamo.utils import warn_once\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n    from . import convert_frame, eval_frame, resume_execution\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n    from torch._dynamo.symbolic_convert import TensorifyState\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 27, in <module>\n    from torch._dynamo.exc import TensorifyScalarRestartAnalysis\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\", line 11, in <module>\n    from .utils import counters\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\", line 66, in <module>\n    import torch.fx.experimental.symbolic_shapes\n  File \"/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 74, in <module>\n    from torch.utils._sympy.functions import (\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/functions.py\", line 18, in <module>\n    import sympy\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/__init__.py\", line 74, in <module>\n    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/polys/__init__.py\", line 124, in <module>\n    from .partfrac import apart, apart_list, assemble_partfrac_list\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/polys/partfrac.py\", line 13, in <module>\n    @xthreaded\n     ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/utilities/decorator.py\", line 76, in xthreaded\n    return threaded_factory(func, False)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/utilities/decorator.py\", line 13, in threaded_factory\n    from sympy.matrices import MatrixBase\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/matrices/__init__.py\", line 22, in <module>\n    from .immutable import ImmutableDenseMatrix, ImmutableSparseMatrix\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/matrices/immutable.py\", line 8, in <module>\n    from sympy.matrices.expressions import MatrixExpr\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/matrices/expressions/__init__.py\", line 3, in <module>\n    from .slice import MatrixSlice\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/matrices/expressions/slice.py\", line 1, in <module>\n    from sympy.matrices.expressions.matexpr import MatrixExpr\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/matrices/expressions/matexpr.py\", line 882, in <module>\n    from .matmul import MatMul\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/matrices/expressions/matmul.py\", line 8, in <module>\n    from sympy.strategies import (rm_id, unpack, typed, flatten, exhaust,\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/strategies/__init__.py\", line 26, in <module>\n    from . import rl\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/strategies/rl.py\", line 6, in <module>\n    from .util import new\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/strategies/util.py\", line 17, in <module>\n    expr_fns = assoc(basic_fns, 'new', lambda op, *args: op(*args))\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sympy/strategies/util.py\", line 6, in assoc\n    def assoc(d, k, v):\n    \nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!ls $TRAIN_DIR/target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:13:33.978347Z","iopub.execute_input":"2025-04-24T10:13:33.978626Z","iopub.status.idle":"2025-04-24T10:13:34.111907Z","shell.execute_reply.started":"2025-04-24T10:13:33.978601Z","shell.execute_reply":"2025-04-24T10:13:34.111231Z"}},"outputs":[{"name":"stdout","text":"mask.png  target.png\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# See the output model\n!ls $OUTPUT_DIR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:13:29.861196Z","iopub.execute_input":"2025-04-24T10:13:29.861878Z","iopub.status.idle":"2025-04-24T10:13:29.996021Z","shell.execute_reply.started":"2025-04-24T10:13:29.861835Z","shell.execute_reply":"2025-04-24T10:13:29.995309Z"}},"outputs":[{"name":"stdout","text":"checkpoint-100\t checkpoint-1600  checkpoint-400     logs\ncheckpoint-1000  checkpoint-1700  checkpoint-500     model_index.json\ncheckpoint-1100  checkpoint-1800  checkpoint-600     scheduler\ncheckpoint-1200  checkpoint-1900  checkpoint-700     text_encoder\ncheckpoint-1300  checkpoint-200   checkpoint-800     tokenizer\ncheckpoint-1400  checkpoint-2000  checkpoint-900     unet\ncheckpoint-1500  checkpoint-300   feature_extractor  vae\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# For inference\n\n!accelerate launch infer.py \\\n    --model_path=$OUTPUT_DIR \\\n    --validation_image=$VAL_IMG \\\n    --validation_mask=$VAL_MASK \\\n    --output_dir=$OUTPUT_IMG_DIR","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3m023PQGd_H1","outputId":"1e5a8023-d02b-4d4a-d8e0-8a1b96f147d8","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:46:52.553983Z","iopub.execute_input":"2025-04-24T14:46:52.554264Z","iopub.status.idle":"2025-04-24T14:48:06.902706Z","shell.execute_reply.started":"2025-04-24T14:46:52.554240Z","shell.execute_reply":"2025-04-24T14:48:06.901995Z"}},"outputs":[{"name":"stdout","text":"2025-04-24 14:47:09.176446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745506029.416794     108 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745506029.490238     108 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nmodel_index.json: 100%|████████████████████████| 544/544 [00:00<00:00, 4.60MB/s]\nFetching 13 files:   0%|                                 | 0/13 [00:00<?, ?it/s]\nmodel.safetensors:   0%|                            | 0.00/1.36G [00:00<?, ?B/s]\u001b[A\n\nmerges.txt:   0%|                                    | 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\n\n\npreprocessor_config.json: 100%|████████████████| 342/342 [00:00<00:00, 2.21MB/s]\u001b[A\u001b[A\u001b[A\n\n\n\nFetching 13 files:   8%|█▉                       | 1/13 [00:00<00:02,  4.59it/s]\u001b[A\u001b[A\u001b[A\n\n\n\nscheduler_config.json: 100%|███████████████████| 308/308 [00:00<00:00, 2.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nconfig.json: 100%|█████████████████████████████| 638/638 [00:00<00:00, 5.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ntokenizer_config.json: 100%|███████████████████| 829/829 [00:00<00:00, 5.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nspecial_tokens_map.json: 100%|█████████████████| 460/460 [00:00<00:00, 3.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\nmodel.safetensors:   2%|▎                   | 21.0M/1.36G [00:00<00:09, 135MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:   0%|           | 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\nmerges.txt: 100%|████████████████████████████| 525k/525k [00:00<00:00, 3.04MB/s]\u001b[A\u001b[A\n\n\nconfig.json: 100%|█████████████████████████████| 616/616 [00:00<00:00, 3.20MB/s]\u001b[A\u001b[A\n\nmodel.safetensors:   3%|▌                   | 41.9M/1.36G [00:00<00:09, 141MB/s]\u001b[A\n\nconfig.json: 100%|█████████████████████████████| 914/914 [00:00<00:00, 6.58MB/s]\u001b[A\u001b[A\n\n\n\nvocab.json: 100%|██████████████████████████| 1.06M/1.06M [00:00<00:00, 4.21MB/s]\u001b[A\u001b[A\u001b[A\n\n\n\n\n\ndiffusion_pytorch_model.safetensors:   6%|▏  | 21.0M/335M [00:00<00:02, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   1%|  | 21.0M/3.46G [00:00<00:28, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:   5%|▉                   | 62.9M/1.36G [00:00<00:07, 165MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  13%|▍  | 41.9M/335M [00:00<00:01, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   1%|  | 41.9M/3.46G [00:00<00:21, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:   7%|█▍                  | 94.4M/1.36G [00:00<00:06, 198MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  19%|▌  | 62.9M/335M [00:00<00:01, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   2%|  | 73.4M/3.46G [00:00<00:17, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:   9%|█▉                   | 126M/1.36G [00:00<00:05, 232MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  28%|▊  | 94.4M/335M [00:00<00:01, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  12%|██▍                  | 157M/1.36G [00:00<00:04, 251MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   3%|  | 94.4M/3.46G [00:00<00:19, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  38%|█▌  | 126M/335M [00:00<00:00, 211MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  14%|██▉                  | 189M/1.36G [00:00<00:04, 258MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   4%|   | 126M/3.46G [00:00<00:17, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  47%|█▉  | 157M/335M [00:00<00:00, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  16%|███▍                 | 220M/1.36G [00:01<00:05, 227MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   5%|▏  | 157M/3.46G [00:00<00:16, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  56%|██▎ | 189M/335M [00:00<00:00, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   5%|▏  | 189M/3.46G [00:00<00:15, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  18%|███▉                 | 252M/1.36G [00:01<00:04, 224MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   6%|▏  | 220M/3.46G [00:01<00:13, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  21%|████▎                | 283M/1.36G [00:01<00:04, 227MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  66%|██▋ | 220M/335M [00:01<00:00, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   7%|▏  | 252M/3.46G [00:01<00:13, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  23%|████▊                | 315M/1.36G [00:01<00:04, 230MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  75%|███ | 252M/335M [00:01<00:00, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   8%|▏  | 283M/3.46G [00:01<00:13, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  25%|█████▎               | 346M/1.36G [00:01<00:04, 239MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  85%|███▍| 283M/335M [00:01<00:00, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:   9%|▎  | 315M/3.46G [00:01<00:13, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  28%|█████▊               | 377M/1.36G [00:01<00:04, 239MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  94%|███▊| 315M/335M [00:01<00:00, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  10%|▎  | 346M/3.46G [00:01<00:12, 242MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\ndiffusion_pytorch_model.safetensors: 100%|████| 335M/335M [00:01<00:00, 201MB/s]\u001b[A\n\n\n\n\ndiffusion_pytorch_model.safetensors:  11%|▎  | 377M/3.46G [00:01<00:12, 249MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  32%|██████▊              | 440M/1.36G [00:01<00:03, 246MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  12%|▎  | 419M/3.46G [00:01<00:10, 278MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  35%|███████▎             | 472M/1.36G [00:02<00:03, 260MB/s]\u001b[A\nmodel.safetensors:  37%|███████▊             | 503M/1.36G [00:02<00:03, 273MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  13%|▍  | 461M/3.46G [00:01<00:10, 295MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  14%|▎ | 493M/3.46G [00:03<00:39, 74.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  39%|███████▊            | 535M/1.36G [00:03<00:12, 67.1MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  15%|▎ | 524M/3.46G [00:03<00:31, 92.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  42%|████████▎           | 566M/1.36G [00:03<00:09, 85.9MB/s]\u001b[A\nmodel.safetensors:  44%|█████████▏           | 598M/1.36G [00:03<00:06, 110MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  16%|▍  | 566M/3.46G [00:03<00:23, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  47%|█████████▊           | 640M/1.36G [00:03<00:04, 147MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  18%|▌  | 608M/3.46G [00:03<00:18, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  50%|██████████▌          | 682M/1.36G [00:03<00:03, 178MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  19%|▌  | 650M/3.46G [00:03<00:14, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  20%|▌  | 692M/3.46G [00:03<00:12, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  53%|███████████▏         | 724M/1.36G [00:04<00:03, 209MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  21%|▋  | 734M/3.46G [00:03<00:10, 250MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  56%|███████████▊         | 765M/1.36G [00:04<00:02, 239MB/s]\u001b[A\nmodel.safetensors:  59%|████████████▍        | 807M/1.36G [00:04<00:02, 265MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  22%|▋  | 776M/3.46G [00:04<00:10, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  62%|█████████████        | 849M/1.36G [00:04<00:01, 286MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  24%|▋  | 818M/3.46G [00:04<00:09, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  65%|█████████████▋       | 891M/1.36G [00:04<00:01, 297MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  25%|▋  | 860M/3.46G [00:04<00:08, 296MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  69%|██████████████▍      | 933M/1.36G [00:04<00:01, 304MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  26%|▊  | 902M/3.46G [00:04<00:08, 299MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  72%|███████████████      | 975M/1.36G [00:04<00:01, 316MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  27%|▊  | 944M/3.46G [00:04<00:08, 307MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  75%|██████████████▉     | 1.02G/1.36G [00:04<00:01, 322MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  28%|▊  | 986M/3.46G [00:04<00:07, 320MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  78%|███████████████▌    | 1.06G/1.36G [00:05<00:00, 331MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  30%|▌ | 1.03G/3.46G [00:04<00:07, 318MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  81%|████████████████▏   | 1.10G/1.36G [00:05<00:00, 325MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  31%|▌ | 1.07G/3.46G [00:04<00:07, 327MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  84%|████████████████▊   | 1.14G/1.36G [00:05<00:00, 330MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  32%|▋ | 1.11G/3.46G [00:05<00:07, 335MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  87%|█████████████████▍  | 1.18G/1.36G [00:05<00:00, 328MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  33%|▋ | 1.15G/3.46G [00:05<00:06, 337MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  90%|██████████████████  | 1.23G/1.36G [00:05<00:00, 329MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  35%|▋ | 1.20G/3.46G [00:05<00:06, 336MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  93%|██████████████████▋ | 1.27G/1.36G [00:05<00:00, 331MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  36%|▋ | 1.24G/3.46G [00:05<00:06, 331MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors:  96%|███████████████████▎| 1.31G/1.36G [00:05<00:00, 321MB/s]\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  37%|▋ | 1.28G/3.46G [00:05<00:07, 309MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  38%|▊ | 1.31G/3.46G [00:05<00:07, 299MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nmodel.safetensors: 100%|████████████████████| 1.36G/1.36G [00:06<00:00, 226MB/s]\u001b[A\nFetching 13 files:  38%|█████████▌               | 5/13 [00:06<00:10,  1.30s/it]\n\n\n\ndiffusion_pytorch_model.safetensors:  39%|▊ | 1.34G/3.46G [00:05<00:07, 298MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  40%|▊ | 1.38G/3.46G [00:05<00:06, 309MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  41%|▊ | 1.43G/3.46G [00:06<00:06, 314MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  42%|▊ | 1.46G/3.46G [00:06<00:06, 314MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  43%|▊ | 1.49G/3.46G [00:06<00:06, 313MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  44%|▉ | 1.53G/3.46G [00:06<00:06, 314MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  45%|▍| 1.57G/3.46G [00:07<00:22, 83.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  46%|▍| 1.60G/3.46G [00:09<00:36, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  47%|▍| 1.63G/3.46G [00:10<00:49, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  48%|▍| 1.65G/3.46G [00:10<00:40, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  48%|▍| 1.67G/3.46G [00:10<00:32, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  49%|▍| 1.71G/3.46G [00:10<00:20, 84.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  51%|█ | 1.75G/3.46G [00:10<00:14, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  51%|█ | 1.78G/3.46G [00:10<00:14, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  53%|█ | 1.82G/3.46G [00:11<00:10, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  54%|█ | 1.87G/3.46G [00:11<00:08, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  55%|█ | 1.91G/3.46G [00:11<00:07, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  56%|█▏| 1.95G/3.46G [00:11<00:06, 250MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  58%|█▏| 1.99G/3.46G [00:11<00:05, 273MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  59%|█▏| 2.03G/3.46G [00:11<00:04, 294MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  60%|█▏| 2.08G/3.46G [00:11<00:04, 313MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  61%|█▏| 2.12G/3.46G [00:11<00:04, 321MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  62%|█▏| 2.16G/3.46G [00:12<00:03, 336MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  64%|█▎| 2.20G/3.46G [00:12<00:03, 347MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  65%|█▎| 2.24G/3.46G [00:12<00:03, 352MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  66%|█▎| 2.29G/3.46G [00:12<00:03, 350MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  67%|█▎| 2.33G/3.46G [00:12<00:03, 349MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  68%|█▎| 2.37G/3.46G [00:12<00:03, 359MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  70%|█▍| 2.41G/3.46G [00:12<00:02, 352MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  71%|█▍| 2.45G/3.46G [00:12<00:02, 345MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  72%|█▍| 2.50G/3.46G [00:12<00:02, 338MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  73%|█▍| 2.54G/3.46G [00:13<00:02, 342MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  74%|█▍| 2.58G/3.46G [00:13<00:02, 346MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  76%|█▌| 2.62G/3.46G [00:13<00:02, 342MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  77%|█▌| 2.66G/3.46G [00:13<00:02, 348MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  78%|█▌| 2.71G/3.46G [00:13<00:02, 349MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  79%|█▌| 2.75G/3.46G [00:13<00:02, 349MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  81%|█▌| 2.79G/3.46G [00:13<00:01, 343MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  82%|█▋| 2.83G/3.46G [00:13<00:01, 357MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  83%|█▋| 2.87G/3.46G [00:14<00:01, 367MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  84%|█▋| 2.92G/3.46G [00:14<00:01, 357MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  85%|█▋| 2.96G/3.46G [00:14<00:01, 359MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  87%|█▋| 3.00G/3.46G [00:14<00:01, 357MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  88%|█▊| 3.04G/3.46G [00:14<00:01, 350MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  89%|█▊| 3.08G/3.46G [00:14<00:01, 346MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  90%|█▊| 3.12G/3.46G [00:14<00:00, 341MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  91%|█▊| 3.17G/3.46G [00:14<00:00, 340MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  93%|█▊| 3.21G/3.46G [00:15<00:00, 339MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  94%|█▉| 3.25G/3.46G [00:15<00:00, 333MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  95%|█▉| 3.29G/3.46G [00:15<00:00, 328MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  96%|█▉| 3.33G/3.46G [00:15<00:00, 326MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  97%|█▉| 3.38G/3.46G [00:15<00:00, 327MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors:  99%|█▉| 3.42G/3.46G [00:15<00:00, 323MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ndiffusion_pytorch_model.safetensors: 100%|██| 3.46G/3.46G [00:15<00:00, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\nFetching 13 files: 100%|████████████████████████| 13/13 [00:16<00:00,  1.25s/it]\nLoading pipeline components...: 100%|█████████████| 6/6 [00:00<00:00,  7.34it/s]\n  0%|                                                   | 0/200 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/kaggle/working/APAI3010_Realfill/realfill/infer.py\", line 78, in <module>\n    result = pipe(\n             ^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py\", line 1252, in __call__\n    latent_model_input = torch.cat([latent_model_input, mask, masked_image_latents], dim=1)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 512 for tensor number 2 in the list.\nTraceback (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 8, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n    args.func(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1194, in launch_command\n    simple_launcher(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 780, in simple_launcher\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\nsubprocess.CalledProcessError: Command '['/usr/bin/python3', 'infer.py', '--model_path=flowerwoman-model', '--validation_image=data/flowerwoman/target/target.png', '--validation_mask=data/flowerwoman/target/mask.png', '--output_dir=flowerwoman-results']' returned non-zero exit status 1.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!ls\n\n# !mv flowerwoman-model/tokenizer/tokenizer_config.json flowerwoman-model/tokenizer/config.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:16:13.971250Z","iopub.execute_input":"2025-04-24T10:16:13.971916Z","iopub.status.idle":"2025-04-24T10:16:14.104925Z","shell.execute_reply.started":"2025-04-24T10:16:13.971887Z","shell.execute_reply":"2025-04-24T10:16:14.104188Z"}},"outputs":[{"name":"stdout","text":"APAI3010_Realfill    infer.py\trealfill.zip\t\t train_realfill.py\ndata\t\t     LICENSE\trequirements_kaggle.txt\nflowerwoman-model    model.zip\trequirements.txt\nflowerwoman-results  README.md\ttrain_realfill.ipynb\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Writing to file on Kaggle\n\ncontent = '''import argparse\nimport os\n\nimport torch\nfrom PIL import Image, ImageFilter\nfrom diffusers import (\n    StableDiffusionInpaintPipeline, \n    UNet2DConditionModel,\n    DDPMScheduler\n)\nfrom transformers import CLIPTextModel\n\nparser = argparse.ArgumentParser(description=\"Inference\")\nparser.add_argument(\n    \"--model_path\",\n    type=str,\n    default=None,\n    required=True,\n    help=\"Path to pretrained model or model identifier from huggingface.co/models.\",\n)\nparser.add_argument(\n    \"--validation_image\",\n    type=str,\n    default=None,\n    required=True,\n    help=\"The directory of the validation image\",\n)\nparser.add_argument(\n    \"--validation_mask\",\n    type=str,\n    default=None,\n    required=True,\n    help=\"The directory of the validation mask\",\n)\nparser.add_argument(\n    \"--output_dir\",\n    type=str,\n    default=\"./test-infer/\",\n    help=\"The output directory where predictions are saved\",\n)\nparser.add_argument(\"--seed\", type=int, default=None, help=\"A seed for reproducible inference.\")\n\nargs = parser.parse_args()\n\nif __name__ == \"__main__\":\n    os.makedirs(args.output_dir, exist_ok=True)\n    generator = None \n\n    # create & load model\n    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n        \"stabilityai/stable-diffusion-2-inpainting\",\n        torch_dtype=torch.float32,\n        revision=None\n    )\n\n    pipe.unet = UNet2DConditionModel.from_pretrained(\n        args.model_path, subfolder=\"unet\", revision=None,\n    )\n    pipe.text_encoder = CLIPTextModel.from_pretrained(\n        args.model_path, subfolder=\"text_encoder\", revision=None,\n    )\n    pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n    pipe = pipe.to(\"cuda\")\n\n    if args.seed is not None:\n        generator = torch.Generator(device=\"cuda\").manual_seed(args.seed)\n    \n    image = Image.open(args.validation_image)\n    mask_image = Image.open(args.validation_mask)\n\n    erode_kernel = ImageFilter.MaxFilter(3)\n    mask_image = mask_image.filter(erode_kernel)\n\n    blur_kernel = ImageFilter.BoxBlur(1)\n    mask_image = mask_image.filter(blur_kernel)\n\n    for idx in range(16):\n        result = pipe(\n            prompt=\"a photo of sks\", image=image, mask_image=mask_image, \n            num_inference_steps=200, guidance_scale=1, generator=generator,\n            height=image.size[1], width=image.size[0],\n        ).images[0]\n        \n        result = Image.composite(result, image, mask_image)\n        result.save(f\"{args.output_dir}/{idx}.png\")\n\n    del pipe\n    torch.cuda.empty_cache()'''\n\ndef write_to_file(filename, content):\n    with open(filename, 'w') as file:\n        file.write(content)\n    print(f\"Content written to {filename}\")\n\nwrite_to_file(\"infer.py\", content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:11:36.624164Z","iopub.execute_input":"2025-04-24T10:11:36.624794Z","iopub.status.idle":"2025-04-24T10:11:36.631352Z","shell.execute_reply.started":"2025-04-24T10:11:36.624767Z","shell.execute_reply":"2025-04-24T10:11:36.630612Z"}},"outputs":[{"name":"stdout","text":"Content written to infer.py\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!cat infer.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T14:57:16.735999Z","iopub.execute_input":"2025-04-24T14:57:16.736301Z","iopub.status.idle":"2025-04-24T14:57:16.874724Z","shell.execute_reply.started":"2025-04-24T14:57:16.736276Z","shell.execute_reply":"2025-04-24T14:57:16.874059Z"}},"outputs":[{"name":"stdout","text":"import argparse\nimport os\n\nimport torch\nfrom PIL import Image, ImageFilter\nfrom diffusers import (\n    StableDiffusionInpaintPipeline, \n    UNet2DConditionModel,\n    DDPMScheduler\n)\nfrom transformers import CLIPTextModel\n\nparser = argparse.ArgumentParser(description=\"Inference\")\nparser.add_argument(\n    \"--model_path\",\n    type=str,\n    default=None,\n    required=True,\n    help=\"Path to pretrained model or model identifier from huggingface.co/models.\",\n)\nparser.add_argument(\n    \"--validation_image\",\n    type=str,\n    default=None,\n    required=True,\n    help=\"The directory of the validation image\",\n)\nparser.add_argument(\n    \"--validation_mask\",\n    type=str,\n    default=None,\n    required=True,\n    help=\"The directory of the validation mask\",\n)\nparser.add_argument(\n    \"--output_dir\",\n    type=str,\n    default=\"./test-infer/\",\n    help=\"The output directory where predictions are saved\",\n)\nparser.add_argument(\"--seed\", type=int, default=None, help=\"A seed for reproducible inference.\")\n\nargs = parser.parse_args()\n\nif __name__ == \"__main__\":\n    os.makedirs(args.output_dir, exist_ok=True)\n    generator = None \n\n    # create & load model\n    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n        \"stabilityai/stable-diffusion-2-inpainting\",\n        torch_dtype=torch.float32,\n        revision=None\n    )\n\n    pipe.unet = UNet2DConditionModel.from_pretrained(\n        args.model_path, subfolder=\"unet\", revision=None,\n    )\n    pipe.text_encoder = CLIPTextModel.from_pretrained(\n        args.model_path, subfolder=\"text_encoder\", revision=None,\n    )\n    pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n    pipe = pipe.to(\"cuda\")\n\n    if args.seed is not None:\n        generator = torch.Generator(device=\"cuda\").manual_seed(args.seed)\n    \n    image = Image.open(args.validation_image)\n    mask_image = Image.open(args.validation_mask)\n\n    erode_kernel = ImageFilter.MaxFilter(3)\n    mask_image = mask_image.filter(erode_kernel)\n\n    blur_kernel = ImageFilter.BoxBlur(1)\n    mask_image = mask_image.filter(blur_kernel)\n\n    for idx in range(16):\n        result = pipe(\n            prompt=\"a photo of sks\", image=image, mask_image=mask_image, \n            num_inference_steps=200, guidance_scale=1, generator=generator,\n            height=image.size[1], width=image.size[0],\n        ).images[0]\n        \n        result = Image.composite(result, image, mask_image)\n        result.save(f\"{args.output_dir}/{idx}.png\")\n\n    del pipe\n    torch.cuda.empty_cache()","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}